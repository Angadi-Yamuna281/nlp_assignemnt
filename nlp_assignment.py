# -*- coding: utf-8 -*-
"""NLP ASSIGNMENT

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lZYHKkKmK8Jlt0_seDnwDYe-kSFB28S9
"""

pip install transformers torch

from transformers import MarianMTModel, MarianTokenizer

# Function to load model and tokenizer
def load_model_and_tokenizer(src_lang, tgt_lang):
    model_name = f'Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}'
    model = MarianMTModel.from_pretrained(model_name)
    tokenizer = MarianTokenizer.from_pretrained(model_name)
    return model, tokenizer

# Function for language translation
def translate_text(text, model, tokenizer):
    # Tokenize the input text and prepare it for translation
    inputs = tokenizer.encode(text, return_tensors="pt", truncation=True, padding=True)

    # Translate the text
    translated = model.generate(inputs, num_beams=4, max_length=50, early_stopping=True)

    # Decode the translated text
    translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)

    return translated_text

# Example usage: Translating English to French
src_lang = "en"  # Source language (English)
tgt_lang = "fr"  # Target language (French)

# Load the model and tokenizer
model, tokenizer = load_model_and_tokenizer(src_lang, tgt_lang)

# Sample text to translate
text_to_translate = "Hello, how are you?"

# Perform translation
translated_text = translate_text(text_to_translate, model, tokenizer)

# Print the original and translated text
print(f"Original Text: {text_to_translate}")
print(f"Translated Text: {translated_text}")

from transformers import MarianMTModel, MarianTokenizer

# Function to load model and tokenizer dynamically based on languages
def load_model_and_tokenizer(src_lang, tgt_lang):
    model_name = f'Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}'
    model = MarianMTModel.from_pretrained(model_name)
    tokenizer = MarianTokenizer.from_pretrained(model_name)
    return model, tokenizer

# Function to perform the translation dynamically
def translate_text(text, model, tokenizer):
    # Tokenize the input text and prepare it for translation
    inputs = tokenizer.encode(text, return_tensors="pt", truncation=True, padding=True)

    # Translate the text
    translated = model.generate(inputs, num_beams=4, max_length=50, early_stopping=True)

    # Decode the translated text
    translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)

    return translated_text

# Function to get user input for languages and text to translate
def get_user_input():
    print("Supported language pairs: 'en-fr', 'en-de', 'fr-en', etc.")
    src_lang = input("Enter the source language code (e.g., 'en' for English): ")
    tgt_lang = input("Enter the target language code (e.g., 'fr' for French): ")
    text_to_translate = input("Enter the text you want to translate: ")
    return src_lang, tgt_lang, text_to_translate

# Main function to execute the dynamic translation
def main():
    # Get user input
    src_lang, tgt_lang, text_to_translate = get_user_input()

    # Load the model and tokenizer based on user input
    model, tokenizer = load_model_and_tokenizer(src_lang, tgt_lang)

    # Perform the translation
    translated_text = translate_text(text_to_translate, model, tokenizer)

    # Print the original and translated text
    print(f"\nOriginal Text: {text_to_translate}")
    print(f"Translated Text: {translated_text}")

# Run the program
if __name__ == "__main__":
    main()

from transformers import MarianMTModel, MarianTokenizer

def load_model_and_tokenizer(src_lang, tgt_lang):
    model_name = f'Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}'
    model = MarianMTModel.from_pretrained(model_name)
    tokenizer = MarianTokenizer.from_pretrained(model_name)
    return model, tokenizer
def translate_text(text, model, tokenizer):
    inputs = tokenizer.encode(text, return_tensors="pt", truncation=True, padding=True)
    translated = model.generate(inputs, num_beams=4, max_length=50, early_stopping=True)
    translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)

    return translated_text
def get_user_input():
    print("Supported language pairs: 'en-fr', 'en-de', 'fr-en', etc.")
    src_lang = input("Enter the source language code (e.g., 'en' for English): ")
    tgt_lang = input("Enter the target language code (e.g., 'fr' for French): ")
    text_to_translate = input("Enter the text you want to translate: ")
    return src_lang, tgt_lang, text_to_translate
def main():
    # Get user input
    src_lang, tgt_lang, text_to_translate = get_user_input()
    model, tokenizer = load_model_and_tokenizer(src_lang, tgt_lang)
    translated_text = translate_text(text_to_translate, model, tokenizer)
    print(f"\nOriginal Text: {text_to_translate}")
    print(f"Translated Text: {translated_text}")
if __name__ == "__main__":
    main()